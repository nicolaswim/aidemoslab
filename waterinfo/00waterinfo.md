# Introduction
The demand for AI systems has risen rapidly over the last decade. Companies are investing massive amounts into being able to house these humongous systems (Reference). The training and maintaining (inference is the official term) is done through the use of data centers. These data centers have started scaling up in size and power consumption, and thus also in water and electricity usage. Within the scope of this project, we will be considering these two parameters, carbon footprint and water usage, as they have an interesting trade-off.

# Water Cooling
Traditional HVAC systems (air-controlled cooling systems) are very costly to maintain. So the industry has turned to water cooling systems. These systems are more efficient and cost-effective (Reference). Many different types of water cooling are used in these data centers (e.g., direct water cooling, indirect water cooling, etc.). All of these systems, however, use the evaporation of water to dissipate energy and cool the systems. This is the direct usage of water, however, it is not the only source of water usage. Many of these data centers require enormous amounts of energy in the form of electricity. This electricity is generated by power plants. These power plants require water to cool the systems. This is the indirect usage of water (Reference).

**IMAGE** of cooling systems in the datacenters

The researchers at *UC Riverside* and *UT Arlington* have highlighted the significant water footprint of AI models, emphasizing the urgent need to address freshwater scarcity and underscored the importance of considering both water and carbon footprints for achieving sustainable AI development(Reference). They found that for every 20-50 queries (interactions you have with chatGPT) there is an estimated of 500ml water used.

# Carbon Footprint
The data centers use a lot of electricity to train these AI systems and keep them running to keep up with global demand. How this electricity is generated is very location-dependent. We take the USA as a case study since it not only houses the most data centers in the world, but it clearly outweighs any follow-up in the list (Table + Reference). Electricity generation varies a lot from north to south and from east to west.

**IMAGE** of electricty generation in the USA. 

# Tradeoff
In the USA, many data centers are located in the south. The reasons may be political and economic, but they lie outside the scope of this project. The problem, however, is that these data centers are located in wide-open spaces, like desert land. They generate green energy as they make a lot of use of solar power, which is abundant in these regions. However, water isn't, and this is the big problem. Not only do these data centers use exorbitant amounts of water, they do so in water-deprived places, like the desert (Reference). Thus, creating a conflict with local communities and the environment.

While data centers in the north have abundant water, their electricity generation is often less green and thus emits more carbon. So we find ourselves "balancing water usage versus the water stress of a region versus the carbon intensity of the power" (Reference).

# Complications
Not only is this a complex problem, but discussing the problem seems even harder due to the lack of data. At the moment, the companies do not have to disclose their water usage (Reference). Most of the data centers are not even withholding the information; they do not even measure their water usage. Although a lot of these companies pledged some water sustainability goal, current efforts do not seem to make their case. Measuring the electricity is easier, since the information can be accessed through the grid.

